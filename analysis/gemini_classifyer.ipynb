{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine,text\n",
    "import os\n",
    "import json\n",
    "import vertexai\n",
    "from vertexai.generative_models import GenerativeModel, Part\n",
    "import time\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vertex config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "VERTEX_PROJECT_ID = os.getenv(\"VERTEX_PROJECT_ID\")\n",
    "vertex_region = \"us-west4\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get all video data from database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_string = 'sqlite:///../db/youtube.db'\n",
    "# Create a engine\n",
    "engine = create_engine(db_string)\n",
    "# Create connection\n",
    "conn = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all video data\n",
    "query = text(\"SELECT * FROM video\")\n",
    "video_df = pd.read_sql_query(query, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove shorts and very long format videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_videos_by_duration(df, min_duration=60, max_duration=1800):\n",
    "    \"\"\"\n",
    "    Filter videos DataFrame by duration within a specified range.\n",
    "    \n",
    "    Parameters:\n",
    "        df (DataFrame): The DataFrame containing video data.\n",
    "        min_duration (int): Minimum duration in seconds. Default is 60.\n",
    "        max_duration (int): Maximum duration in seconds. Default is 1800.\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: Filtered DataFrame containing videos with duration within the specified range.\n",
    "    \"\"\"\n",
    "    return df[(df['duration'] >= min_duration) & (df['duration'] <= max_duration)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos_for_labelling_df = filter_videos_by_duration(video_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create traning dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training dataset\n",
    "videos_for_labelling_df = videos_for_labelling_df.head(10_000) # defines the size of the training dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Gemini prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust display options to prevent truncation\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write prompt string\n",
    "prompt_str = \"\"\"You are a classifier, and I want you to classify each of the following data science youtube video titles based on three overarching categories, video_type, video_topic, coding_language\n",
    "\n",
    "\"video_type\": the options for video type are: \n",
    "\n",
    "\"Tutorial\",\n",
    "\"Project\",\n",
    "\"News\",\n",
    "\"Tips\",\n",
    "\"Challenge\",\n",
    "\"Career Advice\",\n",
    "\"Podcast/Interview\n",
    "\n",
    "\"video_topic\": the options for video topic are: \n",
    "\n",
    "\"Statistics and Probability\",\n",
    "\"Machine Learning / AI\",\n",
    "\"Data Wrangling\",\n",
    "\"Data Visualization\",\n",
    "\"Data Mining\",\n",
    "\"Software Engineering\",\n",
    "\"Ethics and Privacy\",\n",
    "\"Cloud Computing\",\n",
    "\"Resume Building\",\n",
    "\"Job Search Strategies\",\n",
    "\"Interview Techniques\",\n",
    "\"Career Development Paths\",\n",
    "\"Balancing Work and Life\",\n",
    "\"Business Acumen\",\n",
    "\n",
    "\"technologies\": also pull out any software/coding_language/packages as a list called 'technologies'. This should not include anything other than software / coding_language / packages though.\n",
    "\n",
    "From now on, return the output in JSON format. Do not include the JSON identifier at the start of the output. Only output pure JSON.\n",
    "\n",
    "The response should look like (for example):\n",
    "\n",
    "{\n",
    "  \"videos\": [\n",
    "    {\n",
    "      \"video_id\": \"YdWkUdMxMvM\",\n",
    "      \"video_title\": \"Career Change to Code - The Complete Guide\",\n",
    "      \"video_info\": {\n",
    "        \"video_type\": \"Career Advice\",\n",
    "        \"video_topic\": \"Software Engineering\",\n",
    "        \"technologies\": []\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"video_id\": \"5rNk7m_zlAg\",\n",
    "      \"video_title\": \"Spring Boot & Spring Data JPA â€“ Complete Course\",\n",
    "      \"video_info\": {\n",
    "        \"video_type\": \"Tutorial\",\n",
    "        \"video_topic\": \"Software Engineering\",\n",
    "        \"technologies\": [\"Spring\", \"Spring Boot\"]\n",
    "      }\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "The video ids and titles are below:\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to generate respone from Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(project_id: str, location: str, prompt) -> str:\n",
    "    # Initialize Vertex AI\n",
    "    vertexai.init(project=project_id, location=location)\n",
    "    # Load the model\n",
    "    multimodal_model = GenerativeModel(\"gemini-1.0-pro\")\n",
    "    # Query the model\n",
    "    response = multimodal_model.generate_content(\n",
    "        [\n",
    "            prompt\n",
    "        ]\n",
    "    )\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "VERTEX_PROJECT_ID='astute-veld-414717'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 9450 rows of 10000...\n",
      "Processed 9500 rows of 10000...\n",
      "Processed 9550 rows of 10000...\n",
      "Processed 9600 rows of 10000...\n",
      "Processed 9650 rows of 10000...\n",
      "Processed 9700 rows of 10000...\n",
      "Processed 9750 rows of 10000...\n",
      "Processed 9800 rows of 10000...\n",
      "Processed 9850 rows of 10000...\n",
      "Processed 9900 rows of 10000...\n",
      "Processed 9950 rows of 10000...\n",
      "Processed 10000 rows of 10000...\n",
      "Completed processing\n"
     ]
    }
   ],
   "source": [
    "# Get total number of videos\n",
    "total_videos = len(videos_for_labelling_df)\n",
    "\n",
    "# Define chunk size\n",
    "chunk_size = 50\n",
    "\n",
    "# Init response list\n",
    "responses = []\n",
    "\n",
    "# Chunk counter\n",
    "chunk_count = 0\n",
    "\n",
    "# Loop through the DataFrame in chunks of 50\n",
    "for chunk_start in range(0, total_videos, chunk_size):\n",
    "    # Get chunk of videos\n",
    "    videos_chunk = videos_for_labelling_df.iloc[chunk_start:chunk_start + chunk_size]\n",
    "\n",
    "    # Init prompt\n",
    "    prompt = prompt_str\n",
    "\n",
    "    # Add video information to prompt\n",
    "    for i, (_, row) in enumerate(videos_chunk.iterrows(), start=1):\n",
    "        video_title = row['video_title']\n",
    "        video_id = row['video_id']\n",
    "        prompt += f'\\nvideo_id : {video_id}, video_title: {video_title}'\n",
    "\n",
    "    # Generate response for the chunk\n",
    "    response_text = generate_response(VERTEX_PROJECT_ID, vertex_region, prompt)\n",
    "\n",
    "    #response_text = response_text.split(\"{\", 1)[1]\n",
    "\n",
    "    # Check if the response ends with \"```\"\n",
    "    if response_text.endswith(\"```\"):\n",
    "        # Remove the ending \"```\"\n",
    "        response_text = response_text[:-3]\n",
    "\n",
    "    # Load with YAML instead of JSON as response normally has trailing comma on last item\n",
    "    video_info_dict = json.loads(response_text)\n",
    "\n",
    "    # Map video_type, video_topic, and technologies to the existing df\n",
    "    for video in video_info_dict['videos']:\n",
    "        video_id = video.get('video_id', '')\n",
    "        \n",
    "        # Get video_info dictionary\n",
    "        video_info = video.get('video_info', {})\n",
    "        \n",
    "        video_type = video_info.get('video_type', '')\n",
    "        video_topic = video_info.get('video_topic', '')\n",
    "        \n",
    "        # Get technologies list\n",
    "        technologies = video_info.get('technologies', [])\n",
    "        technologies_str = ', '.join(technologies) if isinstance(technologies, list) else ''\n",
    "        \n",
    "        # Update the df with the extracted information\n",
    "        videos_for_labelling_df.loc[videos_for_labelling_df['video_id'] == video_id, 'video_type'] = video_type\n",
    "        videos_for_labelling_df.loc[videos_for_labelling_df['video_id'] == video_id, 'video_topic'] = video_topic\n",
    "        videos_for_labelling_df.loc[videos_for_labelling_df['video_id'] == video_id, 'technologies'] = technologies_str\n",
    "\n",
    "    chunk_count += chunk_size\n",
    "\n",
    "    print(f'Processed {chunk_count} rows of {total_videos}...')\n",
    "\n",
    "    # Delay before processing the next chunk\n",
    "    time.sleep(1)\n",
    "\n",
    "print('Completed processing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10000 entries, 57 to 16900\n",
      "Data columns (total 17 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   channel_id       10000 non-null  object \n",
      " 1   video_id         10000 non-null  object \n",
      " 2   video_title      10000 non-null  object \n",
      " 3   description      10000 non-null  object \n",
      " 4   tags             10000 non-null  object \n",
      " 5   published        10000 non-null  object \n",
      " 6   view_count       10000 non-null  float64\n",
      " 7   like_count       9976 non-null   float64\n",
      " 8   favourite_count  10000 non-null  int64  \n",
      " 9   comment_count    9964 non-null   float64\n",
      " 10  duration         10000 non-null  int64  \n",
      " 11  definition       10000 non-null  object \n",
      " 12  caption          10000 non-null  object \n",
      " 13  category_id      10000 non-null  int64  \n",
      " 14  video_type       9281 non-null   object \n",
      " 15  video_topic      8992 non-null   object \n",
      " 16  technologies     9375 non-null   object \n",
      "dtypes: float64(3), int64(3), object(11)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "videos_for_labelling_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop any rows where video_type is empty\n",
    "cleaned_labelled_video_df = videos_for_labelling_df.dropna(subset=['video_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 9281 entries, 57 to 16900\n",
      "Data columns (total 17 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   channel_id       9281 non-null   object \n",
      " 1   video_id         9281 non-null   object \n",
      " 2   video_title      9281 non-null   object \n",
      " 3   description      9281 non-null   object \n",
      " 4   tags             9281 non-null   object \n",
      " 5   published        9281 non-null   object \n",
      " 6   view_count       9281 non-null   float64\n",
      " 7   like_count       9257 non-null   float64\n",
      " 8   favourite_count  9281 non-null   int64  \n",
      " 9   comment_count    9265 non-null   float64\n",
      " 10  duration         9281 non-null   int64  \n",
      " 11  definition       9281 non-null   object \n",
      " 12  caption          9281 non-null   object \n",
      " 13  category_id      9281 non-null   int64  \n",
      " 14  video_type       9281 non-null   object \n",
      " 15  video_topic      8936 non-null   object \n",
      " 16  technologies     9281 non-null   object \n",
      "dtypes: float64(3), int64(3), object(11)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "cleaned_labelled_video_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_labelled_video_df.to_csv('./training_dataset/labelled_video_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
